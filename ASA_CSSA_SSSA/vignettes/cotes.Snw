\documentclass[]{article}
\usepackage{amsmath}
\usepackage[english]{babel}

\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}

<<echo=false,results=hide>>=
#options(useFancyQuotes = "TeX")
#options(useFancyQuotes = FALSE)
library(lme4)
library(ggplot2)
@

\begin{document}
\title{Implementing "A Bayesian Approach for Assessing the Stability of Genotypes"}
\author{Peter Claussen}
\maketitle



\section{Background}  
   Cotes, et al, "A Bayesian Approach for Assessing the Stability of Genotypes", \emph{Crop Sci.} 46:2654-2665 (2006) provide a Bayesian method for analyzing multi-environment variety trials (MET) \cite{cotes.j-2006}.
Quoting from \cite{cotes.j-2006}, the key goals of MET are

\begin{quote}
\begin{itemize}
   \item[i] to estimate and predict yield with high precision
   \item[ii] to determine yield stability and patterns of response
   \item[iii] to select the best genotype to be sown in future years and new localities 
\end{itemize}
\end{quote}

Traditionally, the results of MET are summarized by simple analysis of variance (AOV) using ordinary least squares. However, in the execution of these trials the most common assumptions of AOV are frequently violated. Specifically, the authors cite the problem of incomplete data, associated with the natural loss of experimental units and that  certain genotypes can be evaluated in only some environments. Mixed model analysis and REML estimation is the accepted alternative but is not without flaw. In particular, negative variance estimates sometimes arise from REML methods.

\subsection{Genotype Selection}
Plant breeders use a series of increasingly stringent trials to identify elite or superior genotypes. The process frequently starts with a very large number of potential lines, derived from crosses made among existing elite genotypes or novel varieties with unique traits. A portion of the best performing (usually in terms of gross yield, in mass per acre) are selected for further screening. As screening advances, fewer genotypes are tested under a wider variety of environmental conditions. In the final stages, potential new products - named genotypes to be sold to farmers for agricultural production - are tested alongside existing elite genotypes. 


Additionally, MET frequently violate the common assumption of homogeneity of variances \cite{edwards.j-2006,so-2009}. While REML methods allow for some degree of heterogeneity in variance estimates, the size of most MET makes REML computationally difficult. Thus, Cotes, et al, suggest a Bayesian approach to the analysis of MET.  While they focus on estimating Shukla's stability variances \cite{shukla.g-1972}, these methods are generalizable to the analysis of combined trials where treatment-by-trial interaction and trial specific experimental error are heterogenous.

\section{Example Data}
We use as an example data set results from the SDSU Winter Wheat project. These data come from Crop Performance Trials (CPT) grown during  2003-2006. This data set illustrates many of the problems associated with the analysis of multiple agronomic trials.

I've added the data to a libary I use for testing, this is loaded by
<<CPT data>>=
library(ASA.CSSA.SSSA)
data(cpt)
@

The CPT data set includes an entry for \verb|fill|. This is some unnamed wheat variety that is use to fill out the experimental grid and to provide a buffer zone. We don't analyze these, so they should be removed.
<<Remove fill>>=
cpt.dat <- subset(cpt.dat,!(cpt.dat$entry=="fill"))
cpt.dat$entry <- as.factor(as.character(cpt.dat$entry))
@

Yield data are stored as \verb|GY| (Gross Yield). There are some missing observations, so we'll subset the data.
<<remove missing yield>>=
cpt.dat <- subset(cpt.dat,!is.na(cpt.dat$GY))
@
Examining the full data set, we see that many entries (genotypes) appear only in only one or two seasons.

<<>>=
head(tapply(cpt.dat$GY,list(cpt.dat$entry,cpt.dat$year),length))
@

This is a very unbalanced data set. We can provide some balance by analyzing only those genotypes that are common to all trials. This data set will be only partially balanced (which we denote by the suffix \verb|pbal|) in that not all genotypes are replicated an equal number of times in all trials. Thus, this data set should not be analyzed using linear model AOV. The exact steps for processing are included in my library.

<<load processed data>>=
data(cpt_data)
cpt.pbal <- subset(cpt.pbal,!is.na(cpt.pbal$GY))
cpt.pbal$year <- as.factor(cpt.pbal$year)
@

I've also included, for comparison, a subset where only equally replicated trials are included. This is fully balanced and can be analyzed using OLS AOV.
<<>>=
cpt.bal <- subset(cpt.bal,!is.na(cpt.bal$GY))
cpt.bal$year <- as.factor(cpt.bal$year)
@

Gross yield was record as bushels/acre. To compare results with \cite{cotes.j-2006} we need to convert to Megagrams/hectare.
<<>>=
#convert to Mg ha-1
cpt.pbal$GY <- (cpt.pbal$TW * cpt.pbal$GY)*0.00112
cpt.bal$GY <- (cpt.bal$TW * cpt.bal$GY)*0.00112
@

The partially balanced data set includes a large number of genotypes and environments.
<<>>=
length(levels(cpt.pbal$entry))
length(levels(cpt.pbal$env))
@
Modeling this data following Cotes, et al, will require a large number of parameters - means estimates for each genotype, a variance estimate for each genotype across environments (Shukla's stability variance, according to \cite{cotes.j-2006}) and a unique, heterogeneous error variance for each environment. To make comparing analysis methods more understandable, we'll use, at first, only three genotypes tested in one location over four years.\footnote{When subsetting, R carries the entire list of levels for factors. I use the simple trick of converting factors to string, then back to factors, to remove unused levels from the original data set.}

<<>>=
three.entries <- subset(cpt.pbal, cpt.pbal$entry %in% c("sd97059-2","wesley","sd98102"))
four.trials <- subset(three.entries, three.entries$location == "Brookings")
four.trials$entry <- as.factor(as.character(four.trials$entry))
four.trials$env <- as.factor(as.character(four.trials$env))
four.trials$bloc <- as.factor(as.character(four.trials$bloc))
four.trials<-four.trials[order(four.trials$year),]
head(four.trials)
@
  
SD98102 was ultimately released as "Darrell" \cite{ibrahim-2008b}. This line was first selected based on visual uniformity and appearance from an F4 nursery and initially screened in Early Yield Trials (EYT). EYT are unreplicated trials (each line planted in one plot only, with a check plot - Arapahoe - every 10 plots) in 3 locations in 1998. SD98102 was then screened in Preliminary Yield Trials (2 replicates) in 1999, and in Advanced Yield Trials (3 replicates), 2000-2001 over 6 locations. SD98102 was then entered into CPT for final evaluation.

The CPT trials were analyzed, for release, using mixed models, environments and genotypes fixed and replicates random; analyzed both within year and across year. Only common entries were included.


SD97059-2 was considered for release, but I cannot find any release information.

Wesley \cite{peterson.c-2001} is included as a check genotype. This variety accounted for roughly one third of winter wheat acres planted in South Dakota, 2002-2011 \cite{sdwhtvar11}

\section{Stability}
From \cite{piepho.h-1996} "It is noted that mean yield and stability are two different features of a variety, so mean comparisons are no substitute for stability analysis".

To illustrate the concept of stability, we will plot genotype means (per trial) against the overall trial mean. 
<<calculate combined trial means>>=
stability.entries <- subset(cpt.pbal, cpt.pbal$entry %in% c("sd97059-2","wesley","sd98102"))
trial.means <- tapply(cpt.pbal$GY,list(cpt.pbal$env),mean,na.rm=TRUE)
stability.entries$trial.mean <- trial.means[stability.entries$env]
@

<<fig=TRUE,width=7,height=4>>=
ggplot(stability.entries, aes(trial.mean,GY)) + geom_point(size=2,alpha = 0.4,aes(color=entry)) + geom_smooth(aes(group=entry,linetype=entry,color=entry),size=1.5,method="lm",se = FALSE) + ylab("Genotype Average (Bu/Acre)")+ xlab("Trial Average (Bu/Acre)")
@

The slope of genotype yield against trial mean will be larger in less stable lines, with the slope proportional to variance. If there is no interaction among genotypes and environments, then the slopes for all genotypes will be identical - the regression lines are parallel. If not, then we may see two types of interaction. If we compare SD97059-2 to Wesley, we see that SD97059-2 consistently out-yields Wesley, and that yield difference increases in higher-yielding environments. Comparing SD97059-2 to SD98102, however, we see a cross-over interaction - SD98102 outperforms SD97059-2 in low-yielding environments, but underperforms in high-yield environments. Thus, the relative rank of these genotypes depends on the choice of environment. Since the performance of SD98102 varies less with environment, this genotype can be considered a more stable choice when grows have less certainty about future environments.

<<>>=
lm(GY ~ trial.mean,data=subset(stability.entries,stability.entries$entry=="sd97059-2"))
lm(GY ~ trial.mean,data=subset(stability.entries,stability.entries$entry=="sd98102"))
lm(GY ~ trial.mean,data=subset(stability.entries,stability.entries$entry=="wesley"))
@

Another way to visual stability is to compare histograms:


<<fig=TRUE,echo=FALSE,width=9,height=5>>=
ggplot(stability.entries, aes(GY, colour = entry)) + geom_density(adjust=2) + xlim(-2, 12)
@


<<fig=TRUE,echo=FALSE,width=9,height=5>>=
ggplot(stability.entries, aes(GY, colour = env)) + geom_density(adjust=2) + xlim(-2, 12)
@

Note that the pooled variance of genotypes across all trials are vary similar, but the large part of that variance is account for by the variances among trials. We should also note that the spread of values within individual trials varies considerably.


\section{Advantages of the Bayesian Method}

Cotes, et al, cite specific advantages of Bayesian analysis for MET data:
\begin{itemize}
   \item deals with incomplete GEI data 
   \item avoids negative variance components estimates
   \item includes in the analysis the heterogeneity of within environment error variances
\end{itemize}   

\subsection{Incomplete data}

First, consider the small data set, with three entries in four trials, all entries equally replicated. The analysis of variance based on a linear model is executed in R as 
<<aov small data>>=
four.trials.aov <- aov(GY ~ entry + env + env:entry + env:bloc,data=four.trials)
four.trials.tbl <- anova(four.trials.aov)
four.trials.tbl
@

Given the standard expected mean squares (when environments and replicates are modeled as random effects), we can estimate variance algebraically \cite{mcintosh-1983}. Note, we use the notation from \cite{cotes.j-2006} for number of genotypes ($g$), environments ($a$) and replicates ($b$).

\begin{center}
  \begin{tabular}{lll}
    \textbf{Source} & \textbf{d.f.} & \textbf{Expected Mean Squares} \\
    Genotypes & $g - 1$ & $\sigma_e^2 + b \sigma_{u_3} + a b \theta_{\beta}^2$ \\
    Environments & $a - 1$ & $\sigma_e^2 + g \sigma^2_{u_2} + b \sigma_{u_3} +
    g b \sigma^2_{u_1}$ \\
    Blocks in Environments & $b ( a - 1)$ & $\sigma_e^2 + g \sigma^2_{u_2}$ \\
    GEI & $( a - 1) ( g - 1)$ & $\sigma_e^2 + b \sigma_{u_3}^2$ \\
    Residual & $a ( g - 1) ( g b - g - 1)$ & $\sigma_e^2$ 
  \end{tabular}
\end{center}

<<algebraic variance estimates>>=
g <- 3
a <- 4
b <- 4
env.var <- (four.trials.tbl[2,3]-four.trials.tbl[4,3] - four.trials.tbl[3,3] +four.trials.tbl[5,3])/(g*b)
env.var
bloc.var <- (four.trials.tbl[4,3]-four.trials.tbl[5,3])/g
bloc.var
GEI.var <- (four.trials.tbl[3,3]-four.trials.tbl[5,3])/b
GEI.var
@

These are directly comparable to REML estimates.
<<REML estimates of small data set>>=
four.trials.hom.var1 <- lmer(GY ~ entry + (1 | env) + (1 | entry:env) + (1|env:bloc), data=four.trials)
four.trials.hom.var1
@

But, if we have unbalanced data, then algebraic estimates are invalid. Consider the larger, unbalanced data:
<<AOV and REML unbalanced CPT data>>=
cpt.pbal.aov <- aov(GY ~ entry + env + env:entry + env:bloc, data=cpt.pbal)
cpt.pbal.tbl <- anova(cpt.pbal.aov)
cpt.pbal.tbl
cpt.pbal.g <- length(levels(cpt.pbal$entry))
cpt.pbal.a <- length(levels(cpt.pbal$env))
cpt.pbal.b <- length(levels(cpt.pbal$bloc))
cpt.pbal.GEI.var <- (cpt.pbal.tbl[3,3]-cpt.pbal.tbl[5,3])/cpt.pbal.b
cpt.pbal.bloc.var <- (cpt.pbal.tbl[4,3]-cpt.pbal.tbl[5,3])/cpt.pbal.g
cpt.pbal.env.var <- (cpt.pbal.tbl[2,3]-cpt.pbal.tbl[4,3] - cpt.pbal.tbl[3,3] + cpt.pbal.tbl[5,3])/(cpt.pbal.g*cpt.pbal.b)
cpt.pbal.GEI.var
cpt.pbal.bloc.var
cpt.pbal.env.var
cpt.pbal.hom.var1 <- lmer(GY ~ entry + (1 | env) + (1 | entry:env) + (1|env:bloc), data=cpt.pbal)
print(cpt.pbal.hom.var1,correlation=FALSE)
@

We can compare a Bayesian estimate to AOV and REML, quickly and conveniently, using the \verb|MCMCglmm| library\cite{hadfield.j-04-2010}. This library allows us to specify mixed models using formula similar to the formula passed to AOV and REML.

<<mcmc homogeneous variances>>=
library(MCMCglmm)
hom.mcmc1 <- MCMCglmm(fixed=  GY ~ entry, random = ~ env + env:entry + env:bloc, data=four.trials, verbose=FALSE)
summary(hom.mcmc1)
#summary(MCMCglmm(fixed=  GY ~ entry, random = ~ env + entry:env + env:bloc, data=four.trials))
cpt.pbal.mcmc1 <- MCMCglmm(fixed=  GY ~ entry, random = ~ env + env:entry + env:bloc, data=cpt.pbal, verbose=FALSE)
summary(cpt.pbal.mcmc1)
@

\subsection{Non-negative variance estimates}

Steel and Torrie, \cite{steel.r-1960}, Exercise 16.8.1,
\begin{quotation}
   Twelve strains of soybeans were compared in a randomized complete block experiment with three blocks at each of three locations in North Carolina.
\end{quotation}

I've added this data set to my library. Consider the classical analysis of variance.
<<>>=
data(SteelTorrie)
st.aov <- aov(Yield ~ Variety + Trial + Variety:Trial + Trial:Rep,data=p399)
st.aov.tbl <- anova(st.aov)
st.aov.tbl
@

If we attempt to compute variances algebraically
<<Steel Torrie AOV variance estimates>>=
(st.aov.tbl[3,3]-st.aov.tbl[5,3])/3
(st.aov.tbl[4,3]-st.aov.tbl[5,3])/12
(st.aov.tbl[2,3]-st.aov.tbl[4,3] - st.aov.tbl[3,3] + st.aov.tbl[5,3])/(12*3)
@

REML estimates will typically be constrained.
<<Steel Torrie REML variance estimates>>=
st.lmer <- lmer(Yield ~ Variety + (1 | Trial) + (1 | Variety:Trial) + (1 | Trial:Rep),data=p399)
print(st.lmer,correlation=FALSE)
@


However, using MCMC
<<Steel Torrie MCMC variance estimates>>=
summary(MCMCglmm(fixed = Yield ~ Variety, random = ~ Trial + Variety:Trial + Trial:Rep,data=p399, verbose=FALSE))
@


We haven't yet attempted to model heterogeneous interaction variances; that is, allow genotype $\times$ environment variance to be estimated uniquely for each genotype. This is necessary to provide an estimate for Shukla's stability variance. Shukla \cite{shukla.g-1972} provides an algebraic method based on cell means (that is, the mean of each genotype in each environment) that is comparable to Tukey's 1 d.f. test for additivity. However, it's more convenient to use REML. We can specify independent variances by

<<heterogeneous GEI variances>>=
het.var1 <- lmer(GY ~ entry + (1 | env) + (entry | env) + (1|env:bloc),data=four.trials)
print(het.var1,correlation=FALSE)
het.var1.0 <- lmer(GY ~ entry + (1 | env) + (0 + entry | env) + (1|env:bloc),data=four.trials)
print(het.var1.0,correlation=FALSE)
@

I've specified the random effects using two different encodings. I prefer the second, in that it simplifies interpretation, but the first is typically more computationally robust. In both, however, we have a variance estimate that is effectively 0. This may be a problem of the size of the data. 

This is not a problem with the Bayesian approach.
<<mcmc heterogenous>>=
het.mcmc1 <- MCMCglmm(fixed=  GY ~ entry, random = ~ env + idh(entry):env + env:bloc,data=four.trials, verbose=FALSE)
summary(het.mcmc1)
@

\subsubsection{Performance with large data}
Larger data sets typically provide better estimates of variance components using REML, if more observations contribute to variance. However, REML can take much longer that other methods when heterogeneous variances are needed. 

Compare
<<profile>>=
if(!file.exists("cpt.pbal.het.var.0.Rda")) {
   Rprof("cpt.pbal.hom")
   cpt.pbal.aov <- aov(GY ~ entry + env + entry:env + env:bloc, data=cpt.pbal)
   cpt.pbal.het.var.0 <- lmer(GY ~ entry + (1 | env) + (1 | entry:env) + (1|env:bloc), data=cpt.pbal)
   cpt.pbal.het.mcmc1 <- MCMCglmm(fixed=  GY ~ entry, random = ~ env + entry:env + env:bloc,data=cpt.pbal)
   Rprof(NULL)
   
   Rprof("cpt.pbal.het")
   cpt.pbal.aov <- aov(lm(GY ~ entry + env + entry:env + env:bloc, data=cpt.pbal))
   cpt.pbal.het.var.0 <- lmer(GY ~ entry + (1 | env) + (0 + entry | env) + (1|env:bloc), data=cpt.pbal)
   cpt.pbal.het.mcmc1 <- MCMCglmm(fixed=  GY ~ entry, random = ~ env + idh(entry):env + env:bloc,data=cpt.pbal)
   save(cpt.pbal.aov ,file="cpt.pbal.aov.Rda")
   save(cpt.pbal.het.var.0,file="cpt.pbal.het.var.0.Rda")
   save(cpt.pbal.het.mcmc1,file="cpt.pbal.het.mcmc1.Rda")
   Rprof(NULL)
} else {
   load(file="cpt.pbal.aov.Rda")
   load(file="cpt.pbal.het.var.0.Rda")
   load(file="cpt.pbal.het.mcmc1.Rda")
}
current.prof <- summaryRprof("cpt.pbal.hom")
head(summaryRprof("cpt.pbal.hom")[[2]],n=20)
current.prof <- summaryRprof("cpt.pbal.het")
head(current.prof[[2]],n=30)
@

<<full profile models>>=
summary(cpt.pbal.aov)
print(cpt.pbal.het.var.0,correlation=FALSE)
summary(cpt.pbal.het.mcmc1)
@

\subsection{Heterogeneity of environmental error variances}

First, we consider the analysis of single trials.
<<single trial aov>>=
summary(aov(GY ~ entry + bloc,data=four.trials[four.trials$env=="Brookings 2003",]))
summary(aov(GY ~ entry + bloc,data=four.trials[four.trials$env=="Brookings 2004",]))
summary(aov(GY ~ entry + bloc,data=four.trials[four.trials$env=="Brookings 2005",]))
summary(aov(GY ~ entry + bloc,data=four.trials[four.trials$env=="Brookings 2006",]))
@

Three of the four trials have comparable residual errors. A rough rule of thumb is that variances can be considered homogeneous if the largest error MS is less than three times the smallest\cite{gomez-1984}, that is,

<<quick Ftest>>=
0.4076/0.0978
@

Using strict AOV, we would not be able to provide a combined analysis of these trials; the results from Brookings 2004 would be discarded.


I've found no specific mechanism to allow for heterogeneous residual error using \verb|lmer|. We can allow blocks within environments to be heterogeneous. This may be an acceptable substitute, but does not compare with the approach of \cite{cotes.j-2006}.

<<lmer with heterogenous block error>>=
het.var2 <- lmer(GY ~ entry + (1 | env) + (0 + entry | env) + (0 + env | bloc),data=four.trials)
print(het.var2, correlation=FALSE)
@

In contrast, heterogeneous error variances are is easily added to the \verb|MCMCglmm| model by specifying a residual covariance structure, \verb|rcov|.

First, we specify only blocks as random. This allows us to compare the Bayesian fixed effects estimates to an OLS estimate.

<<fixed GEI mcmc>>=
het.mcmc2 <- MCMCglmm(fixed=  GY ~ entry + env + entry:env, random = ~ env:bloc,data=four.trials,rcov=~idh(env):units, verbose=FALSE)
summary(het.mcmc2)
print(lm(GY ~ entry + env + entry:env,data=four.trials))
@

Next, we consider heterogeneous environment variances.

<<full cotes mcmc>>=
het.mcmc3 <- MCMCglmm(fixed=  GY ~ entry, random = ~ env + idh(entry):env + env:bloc,data=four.trials,rcov=~idh(env):units, verbose=FALSE)
summary(het.mcmc3)
@

This compares quite well with what we would expect for the different estimates, based on partial analysis using AOV and REML, and, for the most part, implements the methods in \cite{cotes.j-2006}.

\SweaveInput{cotes2.Snw}

%Stan Code

%Fixed only model
%To export, stan uses column major
%y <- structure(c(1,2,3,4,5,6), .Dim = c(2,3))


\section{Appendix}
\subsection{MCMCglmm priors}
\verb|MCMCglmm| allows specification of prior parameters, however, I've not gotten this to work for heterogenous models. Some attempts are below.

<<>>=
#prior = list(R = list(V = diag(4), nu = 0, fix = 2), G = list(G1 = list(V = 1, nu = 0.002),G2 = list(V = 1, nu = 0.002),G3 = list(V = 1, nu = 0.002)))
#hom.mcmc1 <- MCMCglmm(fixed=  GY ~ entry, random = ~ env + entry:env + env:bloc,data=four.trials,prior=prior)
prior = list(R = list(V = diag(4), nu = 0, fix = 2), 
             G = list(
                G1 = list(V = 1, nu = 0.002),
                G2 = list(V = 1, nu = 0.002),
                G3 = list(V = 1, nu = 0.002),
                G4 = list(V = 1, nu = 0.002),
                G5 = list(V = 1, nu = 0.002)
                )
            )
prior = list(R = list(V = diag(4), nu = 0, fix = 2), 
             G = list(
                 G1 = list(V = 1, nu = 0.002),
                 G2 = list(V = diag(3), nu = diag(3)),
                 G3 = list(V = 1, nu = 0.002)
                 )
             )

prior = list(R = list(V = diag(4), nu = 0, fix = 2), 
         G = list(G1 = list(V = 1, nu = 0.002)))

#hom.mcmc1 <- MCMCglmm(fixed=  GY ~ entry, random = ~ env + entry:env + env:bloc,data=four.trials,prior=prior)
#summary(MCMCglmm(fixed=  GY ~ entry, random = ~ env,data=four.trials,prior=prior))
summary(MCMCglmm(fixed=  GY ~ entry, random = ~ env,data=four.trials,rcov=~idh(env):units,verbose=FALSE))


prior = list(R = list(V = 1, nu = 0, fix = 1), 
             G = list(G1 = list(V = 1, nu = 0.002)))
summary(MCMCglmm(fixed=  GY ~ entry, random = ~ env,data=four.trials,prior=prior,verbose=FALSE))

#prior = list(R = list(V = 1, nu = 0, fix = 1), 
#         G = list(G1 = list(V = diag(3), nu = 0.002))
#            )
#summary(MCMCglmm(fixed=  GY ~ entry, random = ~ idh(entry):env,data=four.trials,prior=prior))
@


\subsection{nlme}
The \verb|nlme| library offers an alternative mixed model analysis engine, one that preceded \verb|lmer|. It does allow for a structured residual covariance, but doesn't handle nested random effects.
\section{nlme}

<<>>=
detach("package:lme4")
library(nlme)
four.trials$gei <- four.trials$entry:four.trials$env
four.trials$blocks <- four.trials$env:four.trials$bloc

#lme doesnt like this
#lme(fixed=  GY ~ entry, random = ~ 1 | env:entry, data=four.trials)
lme(fixed=  GY ~ entry, random = ~ 1 | gei, data=four.trials)
lme(fixed=  GY ~ entry, random = ~ 1 | gei, weights = varIdent(form = ~1 | env), data=four.trials)

#fails to converge
#lme(fixed=  GY ~ entry, random = ~ 0 + entry | env, weights = varIdent(form = ~1 | env), data=four.trials)

lme(fixed=  GY ~ entry, random =list(entry = ~ 0 + entry | env, blocks = ~ 1 | env:bloc), weights = varIdent(form = ~1 | env), data=four.trials)

lme(fixed=  GY ~ entry, random =list(gei = ~ 1 | entry:env, blocks = ~ 1 | env:bloc), weights = varIdent(form = ~1 | env), data=four.trials)
@


\bibliographystyle{plain}
\bibliography{asa.bib}

\end{document}